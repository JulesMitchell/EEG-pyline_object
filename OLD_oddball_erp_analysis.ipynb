{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne, os\n",
    "from signal_processing.pre_process import *\n",
    "from basic.arrange_data import read_files, create_results_folders\n",
    "import numpy as np\n",
    "from cmath import nan\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "mne.set_log_level('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folder = r\"Auditory Oddball/Baseline\" # in case you want to just type the dir here\n",
    "#exp_folder = input('Experiment folder (e.g., Eyes Open\\Baseline):')\n",
    "\n",
    "raw_folder = r\"Data/Raw/OKTOS/\"\n",
    "clean_folder = r\"Data/Clean/OKTOS\"\n",
    "dir_inprogress = os.path.join(raw_folder,exp_folder)\n",
    "export_dir = os.path.join(clean_folder,exp_folder)\n",
    "\n",
    "results_foldername = r\"Results/OKTOS\"\n",
    "exp_condition = r\"AO_T01\"\n",
    "\n",
    "file_dirs, subject_names = read_files(dir_inprogress,\".bdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_erp_peak(evoked,erp,time_window=[0,0.8],mode='pos',smallunits=True):\n",
    "    if smallunits == True:\n",
    "        time_coef = 1e3 # ms\n",
    "        amplitude_coef= 1e6 # uV\n",
    "    else:\n",
    "        time_coef = 1 # s\n",
    "        amplitude_coef = 1 # V\n",
    "    \n",
    "    try:\n",
    "        _, erp[0], erp[1] = evoked.get_peak(ch_type='eeg',tmin=time_window[0],tmax=time_window[1],mode=mode,return_amplitude=True)\n",
    "        erp[0] = erp[0] * time_coef\n",
    "        erp[1] = erp[1] * amplitude_coef\n",
    "    except:\n",
    "        erp[0],erp[1] = nan,nan\n",
    "\n",
    "    return erp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_inprogress = os.path.join(clean_folder,exp_folder)\n",
    "file_dirs, subject_names = read_files(dir_inprogress,\"_clean-epo.fif\")\n",
    "\n",
    "# Predefinables\n",
    "event_list = ['target after 1 standard','target after 3 standards','target after 5 standards',\n",
    "            'target after 7 standards','target after 9 standards','target after 11 standards']\n",
    "channel_picks = ['Cz'] ### This is the channel we are looking at, Jim told to look Fz, Cz and Pz\n",
    "gfp = False\n",
    "smallunits = True\n",
    "\n",
    "# Time periods to look for ERPs\n",
    "erp_time_n1 = [0.05, 0.15]\n",
    "erp_time_n2 = [0.2, 0.35]\n",
    "erp_time_p2 = [0.15, 0.28]\n",
    "erp_time_p3 = [0.3, 0.5]\n",
    "time_windows_log = str(('N1:',erp_time_n1,'N2:',erp_time_n2,'P2:',erp_time_p2,'P3:',erp_time_p3))\n",
    "\n",
    "# Unit conversion\n",
    "if smallunits == True:\n",
    "    time_unit='ms'\n",
    "    time_coef = 1e3\n",
    "    amplitude_unit='uV'\n",
    "    amplitude_coef= 1e6\n",
    "else:\n",
    "    time_unit='s'\n",
    "    time_coef = 1\n",
    "    amplitude_unit='V'\n",
    "    amplitude_coef = 1\n",
    "\n",
    "# If more than one channel is looked at, then colorcode the plot\n",
    "if len(channel_picks) != 1:\n",
    "    spatial_colors = True\n",
    "else:\n",
    "    spatial_colors = False\n",
    "\n",
    "# Pre-create the variables for evoked objects and arrays to include ERP latencies and amplitudes\n",
    "evoked_tar_grand = [None]*len(file_dirs)\n",
    "evoked_tar = [None]*len(file_dirs)\n",
    "for i in range(len(file_dirs)):\n",
    "    evoked_tar[i] = [None]*len(event_list)\n",
    "n1 = np.zeros(shape=(len(file_dirs),len(event_list),2)) # subject, event type, [latency, amplitude]\n",
    "n2 = np.zeros(shape=(len(file_dirs),len(event_list),2))\n",
    "p2 = np.zeros(shape=(len(file_dirs),len(event_list),2))\n",
    "p3 = np.zeros(shape=(len(file_dirs),len(event_list),2))\n",
    "n1_grand = np.zeros(shape=(len(file_dirs),2))\n",
    "n2_grand = np.zeros(shape=(len(file_dirs),2))\n",
    "p2_grand = np.zeros(shape=(len(file_dirs),2))\n",
    "p3_grand = np.zeros(shape=(len(file_dirs),2))\n",
    "\n",
    "# Go through all the files (subjects) in the folder\n",
    "for i in range(len(file_dirs)):\n",
    "    # Read the clean data from the disk\n",
    "    epochs = mne.read_epochs(fname='{}/{}_clean-epo.fif'.format(dir_inprogress,subject_names[i]),verbose=False)\n",
    "    \n",
    "    ### Find ERPs for the grand average evokeds\n",
    "    evoked_tar_grand[i] = epochs[event_list].average(picks=channel_picks)\n",
    "\n",
    "    # N100 (fronto-central) -> 65-150ms\n",
    "    n1_grand[i] = find_erp_peak(evoked_tar_grand[i],n1_grand[i],time_window=erp_time_n1,mode='neg',smallunits=True)\n",
    "\n",
    "    # N200 (anterior) -> 200-350ms\n",
    "    n2_grand[i] = find_erp_peak(evoked_tar_grand[i],n2_grand[i],time_window=erp_time_n2,mode='neg',smallunits=True)\n",
    "    \n",
    "    # P200 (centro-frontal, parieto-occipital) -> 150-280ms\n",
    "    p2_grand[i] = find_erp_peak(evoked_tar_grand[i],p2_grand[i],time_window=erp_time_p2,mode='pos',smallunits=True)\n",
    "    \n",
    "    # P300 (parietal) -> 300-500ms whereas early window is 300-400ms and late is 380-440ms\n",
    "    p3_grand[i] = find_erp_peak(evoked_tar_grand[i],p3_grand[i],time_window=erp_time_p3,mode='pos',smallunits=True)\n",
    "\n",
    "    ### Find ERPs for the individual events\n",
    "    for e in range(len(event_list)):\n",
    "        evoked_tar[i][e] = epochs[event_list[e]].average(picks=channel_picks)\n",
    "\n",
    "        # N100 (fronto-central) -> 65-150ms\n",
    "        n1[i][e] = find_erp_peak(evoked_tar[i][e],n1[i][e],time_window=erp_time_n1,mode='neg',smallunits=True)\n",
    "        \n",
    "        # N200 (anterior) -> 200-350ms\n",
    "        n2[i][e] = find_erp_peak(evoked_tar[i][e],n2[i][e],time_window=erp_time_n2,mode='neg',smallunits=True)\n",
    "        \n",
    "        # P200 (centro-frontal, parieto-occipital) -> 150-280ms\n",
    "        p2[i][e] = find_erp_peak(evoked_tar[i][e],p2[i][e],time_window=erp_time_p2,mode='pos',smallunits=True)\n",
    "        \n",
    "        # P300 (parietal) -> 300-500ms whereas early window is 300-400ms and late is 380-440ms\n",
    "        p3[i][e] = find_erp_peak(evoked_tar[i][e],p3[i][e],time_window=erp_time_p3,mode='pos',smallunits=True)\n",
    "        \n",
    "    # Plot the averaged evoked objects with peaks\n",
    "    fig, axs = plt.subplots(nrows=len(event_list)+1, ncols=1,figsize=(8, 20), layout='tight')\n",
    "    plt.suptitle('Evoked EEG with marked N1, N2, P2, P3 ({})'.format(subject_names[i]),y=1.01)\n",
    "    for ix, ax in enumerate(axs):\n",
    "        # Grand average of all stimulus\n",
    "        if ix == 0:\n",
    "            evoked_tar_grand[i].plot(axes=ax, show=False, time_unit='ms', titles='Grand average of all stimulus')\n",
    "            ax.plot(n1_grand[i][0], n1_grand[i][1], marker='*', color='b')\n",
    "            ax.axvspan(xmin=erp_time_n1[0]*time_coef,xmax=erp_time_n1[1]*time_coef, facecolor='b', alpha=0.1)\n",
    "            ax.plot(n2_grand[i][0], n2_grand[i][1], marker='*', color='b')\n",
    "            ax.axvspan(xmin=erp_time_n2[0]*time_coef,xmax=erp_time_n2[1]*time_coef, facecolor='c', alpha=0.1)\n",
    "            ax.plot(p2_grand[i][0], p2_grand[i][1], marker='*', color='r')\n",
    "            ax.axvspan(xmin=erp_time_p2[0]*time_coef,xmax=erp_time_p2[1]*time_coef, facecolor='r', alpha=0.1)\n",
    "            ax.plot(p3_grand[i][0], p3_grand[i][1], marker='*', color='r')\n",
    "            ax.axvspan(xmin=erp_time_p3[0]*time_coef,xmax=erp_time_p3[1]*time_coef, facecolor='g', alpha=0.1)\n",
    "        # Separate stimulus averages\n",
    "        else:\n",
    "            title = '{}'.format(event_list[ix-1])\n",
    "            evoked_tar[i][ix-1].plot(axes=ax, time_unit=time_unit, show=False, titles=title)\n",
    "            ax.plot(n1[i][ix-1][0], n1[i][ix-1][1], marker='*', color='b')\n",
    "            ax.axvspan(xmin=erp_time_n1[0]*time_coef,xmax=erp_time_n1[1]*time_coef, facecolor='b', alpha=0.1)\n",
    "            ax.plot(n2[i][ix-1][0], n2[i][ix-1][1], marker='*', color='b')\n",
    "            ax.axvspan(xmin=erp_time_n2[0]*time_coef,xmax=erp_time_n2[1]*time_coef, facecolor='c', alpha=0.1)\n",
    "            ax.plot(p2[i][ix-1][0], p2[i][ix-1][1], marker='*', color='r')\n",
    "            ax.axvspan(xmin=erp_time_p2[0]*time_coef,xmax=erp_time_p2[1]*time_coef, facecolor='r', alpha=0.1)\n",
    "            ax.plot(p3[i][ix-1][0], p3[i][ix-1][1], marker='*', color='r')\n",
    "            ax.axvspan(xmin=erp_time_p3[0]*time_coef,xmax=erp_time_p3[1]*time_coef, facecolor='g', alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_erps = pd.DataFrame()\n",
    "df_erps_grand = pd.DataFrame()\n",
    "for i in range(len(file_dirs)):\n",
    "    # Create a dataframe for individual stimulus conditions\n",
    "    df_erps_temp = pd.DataFrame(np.hstack((n1[i], n2[i], p2[i], p3[i])), columns = ['N1 latency','N1 amplitude',\n",
    "                                                                                    'N2 latency','N2 amplitude',\n",
    "                                                                                    'P2 latency','P2 amplitude',\n",
    "                                                                                    'P3 latency','P3 amplitude'])\n",
    "    df_erps_temp['Stimulus'] = event_list\n",
    "    df_erps_temp['Subject'] = subject_names[i]\n",
    "    df_erps_temp['ERP detect-windows'] = time_windows_log\n",
    "    df_erps = pd.concat([df_erps, df_erps_temp.set_index('Subject')])\n",
    "    \n",
    "    # Create a dataframe for grand average stimulus\n",
    "    df_erps_grand_temp = pd.DataFrame(np.concatenate((n1_grand[i], n2_grand[i], p2_grand[i], p3_grand[i]))).T\n",
    "    df_erps_grand_temp['Subject'] = subject_names[i]\n",
    "    df_erps_grand_temp['ERP detect-windows'] = time_windows_log\n",
    "    df_erps_grand_temp.columns = ['N1 latency','N1 amplitude','N2 latency','N2 amplitude',\n",
    "                                'P2 latency','P2 amplitude','P3 latency','P3 amplitude',\n",
    "                                'Subject','ERP detect-windows']\n",
    "    df_erps_grand = pd.concat([df_erps_grand, df_erps_grand_temp.set_index('Subject')])\n",
    "display(df_erps_grand)\n",
    "display(df_erps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding peaks for N1, N2, P2, P3 ERP components and plotting them to see if the peaks are in a 'logical' place; in case some of the peaks are not detected or are in a place which is not actually 'a peak', the peaks should be found manually. I would propose that to run all the participants at first and then go over visually the plots and write down participants which had a mis-identified peak (and which ERP it was) and afterwards run these participants again with wider time windows for finding the peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual peak detection for averaged signals which are not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name_manual = 'OKTOS_0002_00A_AO'\n",
    "\n",
    "# NEW time periods to look for ERPs\n",
    "erp_time_n1_manual = [0.05, 0.15]\n",
    "erp_time_n2_manual = [0.2, 0.35]\n",
    "erp_time_p2_manual = [0.1, 0.2]\n",
    "erp_time_p3_manual = [0.27, 0.5]\n",
    "time_windows_log_manual = str(('N1:',erp_time_n1_manual,'N2:',erp_time_n2_manual,'P2:',\n",
    "                                erp_time_p2_manual,'P3:',erp_time_p3_manual))\n",
    "\n",
    "# read the epoch, find the peaks the same way and plot\n",
    "n1_grand_manual,n2_grand_manual,p2_grand_manual,p3_grand_manual = [0]*2,[0]*2,[0]*2,[0]*2\n",
    "n1_manual = np.zeros(shape=(len(event_list),2))\n",
    "n2_manual = np.zeros(shape=(len(event_list),2))\n",
    "p2_manual = np.zeros(shape=(len(event_list),2))\n",
    "p3_manual = np.zeros(shape=(len(event_list),2))\n",
    "evoked_tar_manual = [None]*len(event_list)\n",
    "\n",
    "# Read the clean data from the disk\n",
    "epochs = mne.read_epochs(fname='{}/{}_clean-epo.fif'.format(dir_inprogress,subject_name_manual),verbose=False)\n",
    "\n",
    "### Find ERPs for the grand average evokeds\n",
    "evoked_tar_grand_manual = epochs[event_list].average(picks=channel_picks)\n",
    "\n",
    "# N100 (fronto-central) -> 65-150ms\n",
    "n1_grand_manual = find_erp_peak(evoked_tar_grand_manual,n1_grand_manual,time_window=erp_time_n1_manual,mode='neg',smallunits=True)\n",
    "\n",
    "# N200 (anterior) -> 200-350ms\n",
    "n2_grand_manual = find_erp_peak(evoked_tar_grand_manual,n2_grand_manual,time_window=erp_time_n2_manual,mode='neg',smallunits=True)\n",
    "\n",
    "# P200 (centro-frontal, parieto-occipital) -> 150-280ms\n",
    "p2_grand_manual = find_erp_peak(evoked_tar_grand_manual,p2_grand_manual,time_window=erp_time_p2_manual,mode='pos',smallunits=True)\n",
    "\n",
    "# P300 (parietal) -> 300-500ms whereas early window is 300-400ms and late is 380-440ms\n",
    "p3_grand_manual = find_erp_peak(evoked_tar_grand_manual,p3_grand_manual,time_window=erp_time_p3_manual,mode='pos',smallunits=True)\n",
    "\n",
    "### Find ERPs for the individual events\n",
    "for e in range(len(event_list)):\n",
    "    evoked_tar_manual[e] = epochs[event_list[e]].average(picks=channel_picks)\n",
    "\n",
    "    # N100 (fronto-central) -> 65-150ms\n",
    "    n1_manual[e] = find_erp_peak(evoked_tar_manual[e],n1_manual[e],time_window=erp_time_n1_manual,mode='neg',smallunits=True)\n",
    "    \n",
    "    # N200 (anterior) -> 200-350ms\n",
    "    n2_manual[e] = find_erp_peak(evoked_tar_manual[e],n2_manual[e],time_window=erp_time_n2_manual,mode='neg',smallunits=True)\n",
    "    \n",
    "    # P200 (centro-frontal, parieto-occipital) -> 150-280ms\n",
    "    p2_manual[e] = find_erp_peak(evoked_tar_manual[e],p2_manual[e],time_window=erp_time_p2_manual,mode='pos',smallunits=True)\n",
    "    \n",
    "    # P300 (parietal) -> 300-500ms whereas early window is 300-400ms and late is 380-440ms\n",
    "    p3_manual[e] = find_erp_peak(evoked_tar_manual[e],p3_manual[e],time_window=erp_time_p3_manual,mode='pos',smallunits=True)\n",
    "\n",
    "# Plot the averaged evoked objects with peaks\n",
    "#%matplotlib qt\n",
    "fig, axs = plt.subplots(nrows=len(event_list)+1, ncols=1,figsize=(8, 20), layout='tight')\n",
    "plt.suptitle('Evoked EEG with marked N1, N2, P2, P3 ({})'.format(subject_name_manual),y=1.01)\n",
    "for ix, ax in enumerate(axs):\n",
    "    # Grand average of all stimulus\n",
    "    if ix == 0:\n",
    "        evoked_tar_grand_manual.plot(axes=ax, show=False, time_unit='ms', titles='Grand average of all stimulus')\n",
    "        ax.plot(n1_grand_manual[0], n1_grand_manual[1], marker='*', color='b')\n",
    "        ax.axvspan(xmin=erp_time_n1_manual[0]*time_coef,xmax=erp_time_n1_manual[1]*time_coef, facecolor='b', alpha=0.1)\n",
    "        ax.plot(n2_grand_manual[0], n2_grand_manual[1], marker='*', color='b')\n",
    "        ax.axvspan(xmin=erp_time_n2_manual[0]*time_coef,xmax=erp_time_n2_manual[1]*time_coef, facecolor='c', alpha=0.1)\n",
    "        ax.plot(p2_grand_manual[0], p2_grand_manual[1], marker='*', color='r')\n",
    "        ax.axvspan(xmin=erp_time_p2_manual[0]*time_coef,xmax=erp_time_p2_manual[1]*time_coef, facecolor='r', alpha=0.1)\n",
    "        ax.plot(p3_grand_manual[0], p3_grand_manual[1], marker='*', color='r')\n",
    "        ax.axvspan(xmin=erp_time_p3_manual[0]*time_coef,xmax=erp_time_p3_manual[1]*time_coef, facecolor='g', alpha=0.1)\n",
    "    # Separate stimulus averages\n",
    "    else:\n",
    "        title = '{}'.format(event_list[ix-1])\n",
    "        evoked_tar_manual[ix-1].plot(axes=ax, time_unit='ms', show=False, titles=title)\n",
    "        ax.plot(n1_manual[ix-1][0], n1_manual[ix-1][1], marker='*', color='b')\n",
    "        ax.axvspan(xmin=erp_time_n1_manual[0]*time_coef,xmax=erp_time_n1_manual[1]*time_coef, facecolor='b', alpha=0.1)\n",
    "        ax.plot(n2_manual[ix-1][0], n2_manual[ix-1][1], marker='*', color='b')\n",
    "        ax.axvspan(xmin=erp_time_n2_manual[0]*time_coef,xmax=erp_time_n2_manual[1]*time_coef, facecolor='c', alpha=0.1)\n",
    "        ax.plot(p2_manual[ix-1][0], p2_manual[ix-1][1], marker='*', color='r')\n",
    "        ax.axvspan(xmin=erp_time_p2_manual[0]*time_coef,xmax=erp_time_p2_manual[1]*time_coef, facecolor='r', alpha=0.1)\n",
    "        ax.plot(p3_manual[ix-1][0], p3_manual[ix-1][1], marker='*', color='r')\n",
    "        ax.axvspan(xmin=erp_time_p3_manual[0]*time_coef,xmax=erp_time_p3_manual[1]*time_coef, facecolor='g', alpha=0.1)\n",
    "\n",
    "#n1_grand_manual = [nan,nan]\n",
    "#n1_manual[4] = [nan,nan]\n",
    "\n",
    "df_erps_grand.loc[subject_name_manual,['N1 latency','N1 amplitude']] = n1_grand_manual\n",
    "df_erps_grand.loc[subject_name_manual,['N2 latency','N2 amplitude']] = n2_grand_manual\n",
    "df_erps_grand.loc[subject_name_manual,['P2 latency','P2 amplitude']] = p2_grand_manual\n",
    "df_erps_grand.loc[subject_name_manual,['P3 latency','P3 amplitude']] = p3_grand_manual\n",
    "df_erps_grand.loc[subject_name_manual,['ERP detect-windows']] = time_windows_log\n",
    "\n",
    "df_erps.loc[subject_name_manual,['N1 latency','N1 amplitude']] = n1_manual\n",
    "df_erps.loc[subject_name_manual,['N2 latency','N2 amplitude']] = n2_manual\n",
    "df_erps.loc[subject_name_manual,['P2 latency','P2 amplitude']] = p2_manual\n",
    "df_erps.loc[subject_name_manual,['P3 latency','P3 amplitude']] = p3_manual\n",
    "df_erps.loc[subject_name_manual,['ERP detect-windows']] = time_windows_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are satisified with the new peak locations from the plot and/or have manually set some peaks from the block above, the block below will add all the new peak latencies and amplitudes to the main dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-create results folders for spectral analysis data\n",
    "create_results_folders(exp_folder=exp_folder,results_foldername=results_foldername)\n",
    "\n",
    "df_erps_grand.to_excel(r\"{}/{}_grandaverage_erps.xlsx\".format(results_foldername,exp_condition))\n",
    "df_erps.to_excel(r\"{}/{}_conditionaverages_erps.xlsx\".format(results_foldername,exp_condition))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('3.9.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3241cb67ae0df6d6a4171e7d835d18bb25944a27527ff556ba92c6d5c649e0df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
